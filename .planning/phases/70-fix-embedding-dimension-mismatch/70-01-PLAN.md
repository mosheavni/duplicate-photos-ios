---
phase: 70-fix-embedding-dimension-mismatch
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - DuplicatePhotos/Services/EmbeddingService.swift
  - DuplicatePhotos/Services/CacheService.swift
  - DuplicatePhotos/Models/ScanSettings.swift
autonomous: false

must_haves:
  truths:
    - "Scan with 2+ duplicate photos returns at least 1 group"
    - "Self-similarity test (same image) scores approximately 1.0"
    - "Embedding dimension matches actual model output (768)"
  artifacts:
    - path: "DuplicatePhotos/Services/EmbeddingService.swift"
      provides: "Correct embedding extraction from 768-dim model output"
      contains: "embeddingDimension = 768"
    - path: "DuplicatePhotos/Services/CacheService.swift"
      provides: "Cache clearing capability for dimension migration"
      exports: ["clearCache"]
  key_links:
    - from: "EmbeddingService.extractEmbedding"
      to: "MLMultiArray"
      via: "Correct indexing for batch dimension"
      pattern: "multiArray\\.shape"
    - from: "DuplicateDetector"
      to: "CacheService"
      via: "Cache cleared before scan with new dimensions"
---

<objective>
Fix the embedding dimension mismatch that causes scans to return "No duplicates found."

Purpose: The CoreML model outputs 768 dimensions but code truncates to 512, corrupting embeddings. This is the root cause of scan failure.
Output: Working EmbeddingService that correctly extracts 768-dimensional embeddings with proper MLMultiArray handling.
</objective>

<execution_context>
@/Users/Moshe.Avni/.claude/get-shit-done/workflows/execute-plan.md
@/Users/Moshe.Avni/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/research/SUMMARY.md
@DuplicatePhotos/Services/EmbeddingService.swift
@DuplicatePhotos/Services/CacheService.swift
@DuplicatePhotos/Services/SimilarityService.swift
@DuplicatePhotos/Models/ScanSettings.swift
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix embedding dimension and MLMultiArray handling</name>
  <files>DuplicatePhotos/Services/EmbeddingService.swift</files>
  <action>
Update EmbeddingService to correctly handle the 768-dimensional model output:

1. Change `embeddingDimension` from 512 to 768

2. Add shape detection and logging for MLMultiArray:
   - Log `multiArray.shape` to verify dimensions
   - Log `multiArray.count` to confirm total element count

3. Handle potential batch dimension in MLMultiArray:
   - If shape is `[1, 768]` (2D with batch), use multi-index access: `multiArray[[0, i] as [NSNumber]]`
   - If shape is `[768]` (1D), use simple index access: `multiArray[i]`

4. Add diagnostic logging:
   - Log first 5 and last 5 embedding values (non-normalized) to verify varied values
   - Log embedding magnitude before and after normalization
   - Add a warning if magnitude is near zero (indicates corrupted embeddings)

5. Keep the existing L2 normalization logic (it's correct)

Do NOT change the model loading path or Vision request setup - those are working correctly.
  </action>
  <verify>
Build succeeds: `xcodebuild -project DuplicatePhotos.xcodeproj -scheme DuplicatePhotos -destination 'platform=iOS Simulator,name=iPhone 16 Pro' build 2>&1 | tail -20`
  </verify>
  <done>
EmbeddingService.swift has `embeddingDimension = 768`, handles batch dimension in MLMultiArray, and logs shape/values for debugging.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add cache version and auto-clear for dimension change</name>
  <files>DuplicatePhotos/Services/CacheService.swift</files>
  <action>
Update CacheService to handle the dimension migration:

1. Add a cache version constant at the top of the class:
   ```swift
   private let cacheVersion = 2  // Bumped for 768-dim embeddings
   ```

2. Update CachedEmbedding struct to include version:
   ```swift
   struct CachedEmbedding: Codable {
       let assetIdentifier: String
       let embedding: [Float]
       let imageHash: String
       let createdAt: Date
       let version: Int  // Add this field
   }
   ```

3. In `loadCache()`, check version and auto-clear if mismatched:
   - After decoding, check if any entry has wrong version (or missing version field)
   - If version mismatch found, call `clearCache()` and log "Cleared cache due to version mismatch"

4. In `saveEmbedding()`, ensure new entries include current version

5. Add a `getDimensionSize()` method that returns expected dimension (768) - this allows other services to validate embeddings

Do NOT change the cache file location or encoding format.
  </action>
  <verify>
Build succeeds: `xcodebuild -project DuplicatePhotos.xcodeproj -scheme DuplicatePhotos -destination 'platform=iOS Simulator,name=iPhone 16 Pro' build 2>&1 | tail -20`
  </verify>
  <done>
CacheService has version tracking (version=2), auto-clears old cache on dimension mismatch, and provides getDimensionSize() method.
  </done>
</task>

<task type="auto">
  <name>Task 3: Update similarity threshold default</name>
  <files>DuplicatePhotos/Models/ScanSettings.swift</files>
  <action>
Update the default similarity threshold based on research recommendations:

1. Change `similarityThreshold` default from 0.80 to 0.92
   - Research indicates 0.90-0.95 is optimal for near-duplicates
   - 0.92 is a good balance between catching duplicates and avoiding false positives

2. Add a comment explaining the threshold ranges:
   ```swift
   /// Similarity threshold (0.0 to 1.0)
   /// - 0.98+: Exact duplicates only
   /// - 0.90-0.95: Near-duplicates (recommended)
   /// - 0.80-0.90: Similar photos (may include burst sequences)
   /// Default: 0.92 for near-duplicate detection
   var similarityThreshold: Float = 0.92
   ```

Keep all other settings unchanged.
  </action>
  <verify>
Build succeeds: `xcodebuild -project DuplicatePhotos.xcodeproj -scheme DuplicatePhotos -destination 'platform=iOS Simulator,name=iPhone 16 Pro' build 2>&1 | tail -20`
  </verify>
  <done>
ScanSettings.swift has `similarityThreshold = 0.92` with documented threshold ranges.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Fixed embedding dimension mismatch (768 vs 512), added cache versioning with auto-clear, and updated similarity threshold to 0.92.
  </what-built>
  <how-to-verify>
1. Open DuplicatePhotos.xcodeproj in Xcode
2. Build and run on iOS Simulator (Cmd+R)
3. Grant photo library access when prompted
4. Add 2+ duplicate photos to the simulator if not already present:
   - Drag identical image files into Simulator window, or
   - Use Photos app in Simulator to import from Files
5. Tap "Scan for Duplicates" button
6. Check Xcode console for diagnostic output:
   - Should see: `multiArray.shape` logged (expect [1, 768] or [768])
   - Should see: embedding values are varied (not all zeros)
   - Should see: similar pairs found with similarity > 0.92
7. Verify at least 1 duplicate group is displayed in the results

Expected outcome: Scan completes and shows duplicate group(s) containing the test photos.
  </how-to-verify>
  <resume-signal>Type "approved" if duplicates are detected correctly, or describe any issues observed</resume-signal>
</task>

</tasks>

<verification>
- [ ] EmbeddingService uses 768-dimensional embeddings
- [ ] MLMultiArray batch dimension handled correctly
- [ ] Cache auto-clears when dimension version changes
- [ ] Similarity threshold defaults to 0.92
- [ ] Scan with duplicate photos returns groups
- [ ] Console logs show correct embedding shape and values
</verification>

<success_criteria>
1. Scan with 2+ identical photos returns at least 1 duplicate group
2. Self-similarity (same image processed twice) scores approximately 1.0
3. Console shows `multiArray.shape` as [1, 768] or [768]
4. Embedding values in logs are varied, non-zero floats
5. Max similarity between duplicate photos is > 0.92
</success_criteria>

<output>
After completion, create `.planning/phases/70-fix-embedding-dimension-mismatch/70-01-SUMMARY.md`
</output>
